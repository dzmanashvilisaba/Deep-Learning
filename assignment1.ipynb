{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTUYbQLlYUQ-"
      },
      "source": [
        "# CS492(I) Assignment #1: Image Classification using Convolutional Neural Networks (CNNs)\n",
        "---\n",
        "TA : Yoonki Cho (yoonki@kaist.ac.kr)\n",
        "\n",
        "---\n",
        "\n",
        "## Instructions\n",
        "- In this assignment, we will classify the images in CIFAR10 dataset into 10 categories (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck) using Convolutional Neural Networks(CNNs).  \n",
        "\n",
        "- To this end, you need to implement necessary network components (e.g. residual blocks) using nn.Module class and complete whole CNNs with those blocks. Then, you will experiment those network architectures using given train/testing pipeline and report classfication accuracies on the test set.      \n",
        "\n",
        "- In each part, you will be given a starter code for the implementation. Please read the attached illustrations and instructions carefully to implement the codes.  \n",
        "\n",
        "- As you follow the given steps, fill in the section marked ***Px.x*** (e.g. P1.1, P1.2, etc) with the appropriate code. **Note that you can only fill those marked areas, and cannot modify rest of the  skeleton code.**  \n",
        "\n",
        "- In short, you should (1) complete the code, (2) experiment with several configurations of CNNs, and (3) report the final classification accuracies on the CIFAR10 test set.\n",
        "- To start with, you should download this ipynb file into your own google drive.\n",
        "You can save the file into your own google drive by clicking `make a copy(사본만들기)`. Find the copy in your drive, change their name to `assignment1.ipynb`, if their names were changed to e.g. `Copy of assignment1.ipyb` or `assignment1.ipynb의 사본`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3NY7sfLled4"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Prerequisite: change the runtime type to **GPU**.\n",
        "\n",
        "![test](https://docs.google.com/uc?export=download&id=1Jugrjl86L9EY1ePTjH8OVMFq7gmZsoz_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYfj23oOmOr6"
      },
      "source": [
        "---\n",
        "# Prerequisite: mount your gdrive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQdqM8z8ZM6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249dd6dc-da55-4570-e9ff-e3c04b79b8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount drive https://datascience.stackexchange.com/questions/29480/uploading-images-folder-from-my-system-into-google-colab\n",
        "# login with your google account and type authorization code to mount on your google drive.\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W1NJ35eNLmt"
      },
      "source": [
        "---\n",
        "# Prerequisite: setup the `root` directory properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlhMEGFUi-0c"
      },
      "outputs": [],
      "source": [
        "# Specify the directory path where `assignemnt1.ipynb` exists.\n",
        "# For example, if you saved `assignment1.ipynb` in `/gdrive/My Drive/CS492I/assignment1` directory,\n",
        "# then set root = '/gdrive/My Drive/CS492I/assignment1'\n",
        "root = '/gdrive/My Drive/CS492I/assignment1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8ANEG5WmXzS"
      },
      "source": [
        "---\n",
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxNKZxIRYURA"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTx3YvqWYURE"
      },
      "source": [
        "-----\n",
        "\n",
        "# 1.Implementing Network Modules\n",
        "\n",
        "In this assignment, you will implement four modularized blocks and one network class as follows:\n",
        "\n",
        "**Block classes**  \n",
        "(Example) Multilayer perceptron Block (MLPBlock) **To provide a starting point, the solutions for this section are given below.**  \n",
        "(1) Convolutional block (ConvBlock)   \n",
        "(2) Plain residual block (ResBlockPlain)  \n",
        "(3) Residual block with bottleneck (ResBlockBottleneck)  \n",
        "(4) Inception Block (InceptionBlock)\n",
        "\n",
        "**Network class**  \n",
        "(1) MyNetwork\n",
        "\n",
        "In each cell, there is a starter code, a schematic illustration, and instructions that will guide you to implement each module correctly. Specifically, the schematic illustrations are to show you the computational graphs of modules, which give you high-level views on how the modules should be constructed and work. (E.g. which nn.Module to use, or input/output shape of each layer written in italics). Therefore, please read the illustrations and instructions carefully to complete the codes.\n",
        "<!--\n",
        "Below is an example.\n",
        "\n",
        "### Example: ConvLayer Module [(Illustration)](https://docs.google.com/drawings/d/1_aPhPSPgh5-5FEfI_jnfp8r6-wNjY_QYXBT3zzjkHk0/edit?usp=sharing) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o6mOW0_cjaR"
      },
      "source": [
        "## Block class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILjK1Nmx2M6"
      },
      "source": [
        "### (Example) Implement MLP Block [(Illustration)](https://docs.google.com/drawings/d/1gTPLeK0H5ooMcn7CNPysqwr9_07fTqkHE4-T3ZqyhPo/edit?usp=sharing)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yo9_pniOx1kd"
      },
      "outputs": [],
      "source": [
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        \"\"\"\n",
        "        Initialize a basic multi-layer perceptron module components.\n",
        "        Illustration: https://docs.google.com/drawings/d/1gTPLeK0H5ooMcn7CNPysqwr9_07fTqkHE4-T3ZqyhPo/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in input.\n",
        "            2. out_channels (int): Number of channels to be produced.\n",
        "        \"\"\"\n",
        "        #######################################\n",
        "        ## This section is an example.       ##\n",
        "        self.fc1 = nn.Linear(in_channels, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512,128)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.fc3 = nn.Linear(128, out_channels)\n",
        "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "        #######################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feed-forward data 'x' through the module.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): A tensor of shape (B, in_channels)\n",
        "            .\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels).\n",
        "        \"\"\"\n",
        "        #######################################\n",
        "        ## This section is an example.       ##\n",
        "        output = self.act(self.bn1(self.fc1(x)))\n",
        "        output = self.act(self.bn2(self.fc2(output)))\n",
        "        output = self.act(self.bn3(self.fc3(output)))\n",
        "        #######################################\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLCjNVBx2sd"
      },
      "source": [
        "### (1) Implement Convolutional Block[(Illustration)](https://docs.google.com/drawings/d/1MRYBywpuazlldwC11UTa-kuWMWEDsFewDnirKiFX5us/edit?usp=sharing) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaRZybdRx01E"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,\n",
        "                 padding=1):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        \"\"\"\n",
        "        Initialize a basic convolutional layer module components.\n",
        "        Illustration: https://docs.google.com/drawings/d/1MRYBywpuazlldwC11UTa-kuWMWEDsFewDnirKiFX5us/edit?usp=sharing\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "            2. out_channels (int): Number of channels produced.\n",
        "            3. kernel_size (int) : Size of the kernel used in conv layer (Default:3)\n",
        "            4. stride (int) : Stride of the convolution (Default:1)\n",
        "            5. padding (int) : Zero-padding added to both sides of the input (Default:1)\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P1.1. Write your code here  ##\n",
        "        self.cn = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias = False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Feed-forward the data 'x' through the module.\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): A tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W).\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P1.2. Write your code here  ##\n",
        "        output = self.act(self.bn(self.cn(x)))\n",
        "\n",
        "\n",
        "\n",
        "        #################################\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjz2alvvyr6T"
      },
      "source": [
        "### (2) Implement ResBlockPlain [(Illustration)](https://docs.google.com/drawings/d/19FS5w7anbTAF6UrMPdM4fs8nk9x3Lm5KRIODawC4duQ/edit?usp=sharing) (10pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCeMmP-eyqj-"
      },
      "outputs": [],
      "source": [
        "class ResBlockPlain(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ResBlockPlain, self).__init__()\n",
        "        \"\"\"Initialize a residual block module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/19FS5w7anbTAF6UrMPdM4fs8nk9x3Lm5KRIODawC4duQ/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P2.1. Write your code here ##\n",
        "        self.cn1 = nn.Conv2d(in_channels, in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.cn2 = nn.Conv2d(in_channels, in_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(in_channels)\n",
        "        self.act = nn.ReLU()\n",
        "        #################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, in_channels, H, W).\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P2.2. Write your code here ##\n",
        "        residual = x\n",
        "        output = self.cn1(x)\n",
        "        output = self.bn1(output)\n",
        "        output = self.act(output)\n",
        "        output = self.cn2(output)\n",
        "        output = self.bn2(output)\n",
        "        output += residual\n",
        "        output = self.act(output)\n",
        "        ################################\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0yAzCxaysW0"
      },
      "source": [
        "### (3) Implement ResBlockBottleneck [(Illustration)](https://docs.google.com/drawings/d/1n2E0TwiWhf1IGdD16-MeQjzUcys_V7ETTzn33j_bEy0/edit?usp=sharing) (10pt)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDNU2zPTy_8n"
      },
      "outputs": [],
      "source": [
        "class ResBlockBottleneck(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels):\n",
        "        super(ResBlockBottleneck, self).__init__()\n",
        "        \"\"\"Initialize a residual block module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1n2E0TwiWhf1IGdD16-MeQjzUcys_V7ETTzn33j_bEy0/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "            2. hidden_channels (int): Number of hidden channels produced by the first ConvLayer module.\n",
        "        \"\"\"\n",
        "        #################################\n",
        "        ## P3.1. Write your code here  ##\n",
        "        self.cn1 = nn.Conv2d(in_channels, hidden_channels, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
        "\n",
        "        self.cn2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
        "\n",
        "        self.cn3 = nn.Conv2d(hidden_channels, in_channels, kernel_size =1 , stride = 1, padding = 0, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(in_channels)\n",
        "        self.act = nn.ReLU()\n",
        "        #################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, in_channels, H, W).\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P3.2. Write your code here ##\n",
        "        residual = x\n",
        "        output = self.act(self.bn1(self.cn1(x)))\n",
        "        output = self.act(self.bn2(self.cn2(output)))\n",
        "        output = self.bn3(self.cn3(output))\n",
        "        output += residual\n",
        "        output = self.act(output)\n",
        "        ################################\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkXfj1KsytsU"
      },
      "source": [
        "### (4) Implement InceptionBlock[(Illustration)](https://docs.google.com/drawings/d/1I020R1YqVAr8LWKHgm7N5J5fzFpHvx1fqXuAs6z8qyE/edit?usp=sharing)  (20pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nLdTePuyrCX"
      },
      "outputs": [],
      "source": [
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        \"\"\"Initialize a basic InpcetionBlock module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1I020R1YqVAr8LWKHgm7N5J5fzFpHvx1fqXuAs6z8qyE/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. in_channels (int): Number of channels in the input.\n",
        "            2. out_channels (int): Number of channels in the final output.\n",
        "        \"\"\"\n",
        "        assert out_channels%8==0, 'out channel should be mutiplier of 8'\n",
        "\n",
        "        ################################\n",
        "        ## P4.1. Write your code here ##\n",
        "        dim = out_channels//4\n",
        "        self.cn_1 = nn.Conv2d(in_channels, dim, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.bn_1 = nn.BatchNorm2d(dim)\n",
        "\n",
        "        dim = out_channels//2\n",
        "        self.cn_2 = nn.Conv2d(in_channels, dim, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.bn_2_0 = nn.BatchNorm2d(dim)\n",
        "        self.cn3 = nn.Conv2d(dim, dim, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn_2_1 = nn.BatchNorm2d(dim)\n",
        "\n",
        "        dim = out_channels//8\n",
        "        self.cn_3 = nn.Conv2d(in_channels, dim, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.bn_3_0 = nn.BatchNorm2d(dim)\n",
        "        self.cn5 = nn.Conv2d(dim, dim, kernel_size = 5, stride = 1, padding = 2, bias = False)\n",
        "        self.bn_3_1 = nn.BatchNorm2d(dim)\n",
        "\n",
        "        self.mp = nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.cn_4 = nn.Conv2d(in_channels, dim, kernel_size = 1, stride = 1, padding = 0, bias = False)\n",
        "        self.bn_4 = nn.BatchNorm2d(dim)\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "        self.conv1x1 = nn.Sequential(self.cn_1, self.bn_1, self.act)\n",
        "        self.conv3x3 = nn.Sequential(self.cn_2, self.bn_2_0, self.act, self.cn3, self.bn_2_1, self.act)\n",
        "        self.conv5x5 = nn.Sequential(self.cn_3, self.bn_3_0, self.act, self.cn5, self.bn_3_1, self.act)\n",
        "        self.maxpool = nn.Sequential(self.mp, self.cn_4, self.bn_4, self.act)\n",
        "        ################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the module.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized components in the __init__ method.\n",
        "\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): A tensor of shape (B, in_channels, H, W).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, out_channels, H, W).\n",
        "\n",
        "        \"\"\"\n",
        "        ################################\n",
        "        ## P4.2. Write your code here ##\n",
        "        out1 = self.conv1x1(x)\n",
        "        out2 = self.conv3x3(x)\n",
        "        out3 = self.conv5x5(x)\n",
        "        out4 = self.maxpool(x)\n",
        "        output = torch.cat([out1, out2, out3, out4], 1)\n",
        "        ################################\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5irFIyBYc2nM"
      },
      "source": [
        "## Network class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXSb4yHIYURW"
      },
      "source": [
        "### (Example) MyNetworkExample\n",
        "\n",
        "The class `MyNetworkExample` is a sample network using `MLPBlock` implemented above. **You don't have to implement anything in this code section.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EVcyU6UE_N3"
      },
      "outputs": [],
      "source": [
        "class MyNetworkExample(nn.Module):\n",
        "    def __init__(self, nf, block_type='mlp'):\n",
        "        super(MyNetworkExample, self).__init__()\n",
        "        \"\"\"Initialize an entire network module components.\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. nf (int): Number of input channels for the first nn.Linear Module. An abbreviation for num_filter.\n",
        "            2. block_type (str, optional): Type of blocks to use. ('mlp'. default: 'mlp')\n",
        "        \"\"\"\n",
        "        #######################################\n",
        "        ## This section is an example.       ##\n",
        "        if block_type == 'mlp':\n",
        "            block = MLPBlock\n",
        "            # Since shape of input image is 3 x 32 x 32, the size of flattened input is 3*32*32.\n",
        "            self.mlp = block(3*32*32, nf)\n",
        "            self.fc = nn.Linear(nf, 10)\n",
        "        else:\n",
        "            raise Exception(f\"Wrong type of block: {block_type}.Expected : mlp\")\n",
        "        #######################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized network components in __init__ method.\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An image tensor of shape (B, 3, 32, 32).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, 10).\n",
        "        \"\"\"\n",
        "        #######################################\n",
        "        ## This section is an example.       ##\n",
        "        output = self.mlp(x.view(x.size()[0], -1))\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "        #######################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbSoxtKYU_gG"
      },
      "source": [
        "### (1) MyNetwork[(Illustration)](https://docs.google.com/drawings/d/1L8PYO8A1EL4BN4bzTWH4ygr-WiS7NDeFz7P1PkhBZwE/edit?usp=sharing) (10pt)\n",
        "\n",
        "There are two functions to implement in this section. **Read the comments and illustration carefully before you type anything.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvdXrQUqYURW"
      },
      "outputs": [],
      "source": [
        "class MyNetwork(nn.Module):\n",
        "    def __init__(self, nf, block_type='conv', num_blocks=[1, 1, 1]):\n",
        "        super(MyNetwork, self).__init__()\n",
        "        \"\"\"Initialize an entire network module components.\n",
        "\n",
        "        Illustration: https://docs.google.com/drawings/d/1L8PYO8A1EL4BN4bzTWH4ygr-WiS7NDeFz7P1PkhBZwE/edit?usp=sharing\n",
        "\n",
        "        Instructions:\n",
        "            1. Implement an algorithm that initializes necessary components as illustrated in the above link.\n",
        "            2. Initialized network components will be referred in `forward` method\n",
        "               for constructing the dynamic computational graph.\n",
        "\n",
        "        Args:\n",
        "            1. nf (int): Number of output channels for the first nn.Conv2d Module. An abbreviation for num_filter.\n",
        "            2. block_type (str, optional): Type of blocks to use. ('conv' | 'resPlain' | 'resBottleneck' | 'inception'. default: 'conv')\n",
        "            3. num_blocks (list or tuple, optional): A list or tuple of length 3.\n",
        "               Each item at i-th index indicates the number of blocks at i-th Layer.\n",
        "               (default: [1, 1, 1])\n",
        "        \"\"\"\n",
        "\n",
        "        self.block_type = block_type\n",
        "\n",
        "        # Define blocks according to block_type\n",
        "        if self.block_type == 'conv':\n",
        "            block = ConvBlock\n",
        "            block_args = lambda x: (x, x, 3, 1, 1)\n",
        "        elif self.block_type == 'resPlain':\n",
        "            block = ResBlockPlain\n",
        "            block_args = lambda x: (x,)\n",
        "        elif self.block_type == 'resBottleneck':\n",
        "            block = ResBlockBottleneck\n",
        "            block_args = lambda x: (x, x//2)\n",
        "        elif self.block_type == 'inception':\n",
        "            block = InceptionBlock\n",
        "            block_args = lambda x: (x, x)\n",
        "        else:\n",
        "            raise Exception(f\"Wrong type of block: {block_type}\")\n",
        "\n",
        "        # Define block layer by stacking multiple blocks.\n",
        "        # You don't need to modify it. Just use these block layers in forward function.\n",
        "        self.block1 = nn.Sequential(*[block(*block_args(nf)) for _ in range(num_blocks[0])])\n",
        "        self.block2 = nn.Sequential(*[block(*block_args(nf*2)) for _ in range(num_blocks[1])])\n",
        "        self.block3 = nn.Sequential(*[block(*block_args(nf*4)) for _ in range(num_blocks[2])])\n",
        "\n",
        "        ################################\n",
        "        ## P5.1. Write your code here ##\n",
        "        self.cn1 = nn.Conv2d(3,nf, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(nf)\n",
        "        self.mp1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.cn2 = nn.Conv2d(nf, nf*2, kernel_size = 3, stride = 1, padding = 1,bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(nf*2)\n",
        "        self.mp2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.cn3 = nn.Conv2d(nf*2, nf*4, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(nf*4)\n",
        "        self.mp3 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "        self.avg = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "        self.flt = nn.Flatten()\n",
        "        self.lin = nn.Linear(nf*4, 10)\n",
        "        ################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Feed-forward the data `x` through the network.\n",
        "\n",
        "        Instructions:\n",
        "            1. Construct the feed-forward computational graph as illustrated in the link\n",
        "               using the initialized network components in __init__ method.\n",
        "        Args:\n",
        "            1. x (torch.FloatTensor): An image tensor of shape (B, 3, 32, 32).\n",
        "\n",
        "        Returns:\n",
        "            1. output (torch.FloatTensor): An output tensor of shape (B, 10).\n",
        "        \"\"\"\n",
        "\n",
        "        #######################################################################\n",
        "        ## P5.2. Write your code here                                        ##\n",
        "        ## Hint : use self.block1, self.block2, self.block3 for block layers ##\n",
        "        output = self.cn1(x)\n",
        "        output = self.bn1(output)\n",
        "        output = self.act(output)\n",
        "        output = self.mp1(output)\n",
        "        output = self.block1(output)\n",
        "\n",
        "        output = self.block2(self.mp2(self.act((self.bn2(self.cn2(output))))))\n",
        "        output = self.block3(self.mp3(self.act((self.bn3(self.cn3(output))))))\n",
        "        output = self.lin(self.flt(self.avg(output)))\n",
        "        #######################################################################\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_kBr92qYURi"
      },
      "source": [
        "---\n",
        "\n",
        "# 2.Experiment with Train/Test Pipeline\n",
        "\n",
        "This section contains the entire train and test loop of the pipeline, specifically the followings:\n",
        "1. feed inputs into the network, get outputs, and then compute classification loss.\n",
        "2. backward the computed loss and update network weights (only in the training loop).\n",
        "3. save tensorboard logs frequently.\n",
        "4. save checkpoint weights frequently.\n",
        "\n",
        "**There are no modifications necessary in this section.** Run the code and enjoy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcFgC8fd4gsr"
      },
      "source": [
        "## Arguments and Environment Settings\n",
        "\n",
        "This section contains code that\n",
        "- defines miscellaneous arguments for our pipeline.\n",
        "- runs Tensorboard to visualize accuracy and loss curves.\n",
        "\n",
        "Optionally, you may change `args.ckpt_iter` and `args.`log_iter` as you wish to save space in your Google Drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vcdKxr7YURj"
      },
      "outputs": [],
      "source": [
        "# Configurations & Hyper-parameters\n",
        "\n",
        "from easydict import EasyDict as edict\n",
        "\n",
        "# set manual seeds\n",
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)\n",
        "\n",
        "args = edict()\n",
        "\n",
        "# basic options\n",
        "args.name = 'main'                   # experiment name.\n",
        "args.ckpt_dir = 'ckpts'              # checkpoint directory name.\n",
        "args.ckpt_iter = 1000                # how frequently checkpoints are saved.\n",
        "args.ckpt_reload = 'best'            # which checkpoint to re-load.\n",
        "args.gpu = True                      # whether or not to use gpu.\n",
        "\n",
        "# network options\n",
        "args.num_filters = 16                # number of output channels in the first nn.Conv2d module in MyNetwork.\n",
        "args.block_type = 'mlp'              # type of block. ('mlp' | 'conv' | 'resPlain' | 'resBottleneck' | 'inception').\n",
        "args.num_blocks = [5, 5, 5]          # number of blocks in each Layer.\n",
        "\n",
        "# data options\n",
        "args.dataroot = 'dataset/cifar10'    # where CIFAR10 images exist.\n",
        "args.batch_size = 128                # number of mini-batch size.\n",
        "\n",
        "# training options\n",
        "args.lr = 0.1                        # learning rate.\n",
        "args.epoch = 100                     # training epoch.\n",
        "\n",
        "# tensorboard options\n",
        "args.tensorboard = True              # whether or not to use tensorboard logging.\n",
        "args.log_dir = 'logs'                # to which tensorboard logs will be saved.\n",
        "args.log_iter = 100                  # how frequently logs are saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-acigO4YURl"
      },
      "outputs": [],
      "source": [
        "# Basic settings\n",
        "device = 'cuda' if torch.cuda.is_available() and args.gpu else 'cpu'\n",
        "\n",
        "result_dir = Path(root) / 'results'\n",
        "result_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "global_step = 0\n",
        "best_accuracy = 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOTK_7HjYURv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "f62ee4785cbf45b091fd60eeb9bbabc8",
            "fd2fa7ae77f0401c95f91f341e9b79de",
            "bb67ef30359040d786182eb6bb66e8fc",
            "84aa8f6385694afb9ca4344f396f2421",
            "ea21326b532c4b10999496a8f8a2b0ef",
            "5b57a13481e5442fb98e0a9d47572090",
            "83357e5c6c8c4ed1a71f2d3a98727511",
            "95dcaf479aa646da92b3c1b6fb4ec87c",
            "fdcb5a5b8d3546389c919f476e954b26",
            "26489d53690e4e0b881c394fcef52d75",
            "f4f6f75e5881442f903e3b5176b03083"
          ]
        },
        "outputId": "b3f7bde6-476f-449b-9d9c-4a068e6ec3ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f62ee4785cbf45b091fd60eeb9bbabc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset/cifar10/cifar-10-python.tar.gz to dataset/cifar10\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Define train/test data loaders\n",
        "# Use data augmentation in training set to mitigate overfitting.\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "    ])\n",
        "\n",
        "train_dataset = CIFAR10(args.dataroot, download=True, train=True, transform=train_transform)\n",
        "test_dataset = CIFAR10(args.dataroot, download=True, train=False, transform=test_transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqZmn8qQdBji"
      },
      "source": [
        "## Tracking the states with Tensorboard\n",
        "\n",
        "In following training stage, losses and accuracies will be logged on the tensorboard. It provides an useful data for analyzing training process.\n",
        "Use tensorboard wisely.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0Ih-Yg0YURn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99b736e-28b7-4ac5-b250-534acf1cfa59"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Setup tensorboard.\n",
        "if args.tensorboard:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir \"/gdrive/My Drive/{str(result_dir).replace('/gdrive/My Drive/', '')}\"\n",
        "else:\n",
        "    writer = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmrnUO_55yix"
      },
      "source": [
        "## The Train-and-Test pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-ukFLINYURx"
      },
      "outputs": [],
      "source": [
        "def train_net(net, optimizer, scheduler, block_type, writer):\n",
        "    global_step = 0\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for epoch in range(args.epoch):\n",
        "        # Here starts the train loop.\n",
        "        net.train()\n",
        "        for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            #  Send `x` and `y` to either cpu or gpu using `device` variable.\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            # Feed `x` into the network, get an output, and keep it in a variable called `logit`.\n",
        "            logit = net(x)\n",
        "\n",
        "            # Compute accuracy of this batch using `logit`, and keep it in a variable called 'accuracy'.\n",
        "            accuracy = (logit.argmax(1) == y).float().mean()\n",
        "\n",
        "            # Compute loss using `logit` and `y`, and keep it in a variable called `loss`.\n",
        "            loss = nn.CrossEntropyLoss()(logit, y)\n",
        "\n",
        "            # flush out the previously computed gradient.\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # backward the computed loss.\n",
        "            loss.backward()\n",
        "\n",
        "            # update the network weights.\n",
        "            optimizer.step()\n",
        "\n",
        "            if global_step % args.log_iter == 0 and writer is not None:\n",
        "                # Log loss and accuracy values using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                writer.add_scalar('train_loss', loss, global_step)\n",
        "                writer.add_scalar('train_accuracy', accuracy, global_step)\n",
        "\n",
        "            if global_step % args.ckpt_iter == 0:\n",
        "                # Save network weights in the directory specified by `ckpt_dir` directory.\n",
        "                torch.save(net.state_dict(), f'{ckpt_dir}/{global_step}.pt')\n",
        "\n",
        "        # Here starts the test loop.\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            test_loss = 0.\n",
        "            test_accuracy = 0.\n",
        "            test_num_data = 0.\n",
        "            for batch_idx, (x, y) in enumerate(test_dataloader):\n",
        "                # Send `x` and `y` to either cpu or gpu using `device` variable..\n",
        "                x = x.to(device=device)\n",
        "                y = y.to(device=device)\n",
        "\n",
        "                # Feed `x` into the network, get an output, and keep it in a variable called `logit`.\n",
        "                logit = net(x)\n",
        "\n",
        "                # Compute loss using `logit` and `y`, and keep it in a variable called `loss`.\n",
        "                loss = nn.CrossEntropyLoss()(logit, y)\n",
        "\n",
        "                # Compute accuracy of this batch using `logit`, and keep it in a variable called 'accuracy'.\n",
        "                accuracy = (logit.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "                test_loss += loss.item()*x.shape[0]\n",
        "                test_accuracy += accuracy.item()*x.shape[0]\n",
        "                test_num_data += x.shape[0]\n",
        "\n",
        "            test_loss /= test_num_data\n",
        "            test_accuracy /= test_num_data\n",
        "\n",
        "            if writer is not None:\n",
        "                # Log loss and accuracy values using `writer`. Use `global_step` as a timestamp for the log.\n",
        "                writer.add_scalar('test_loss', test_loss, global_step)\n",
        "                writer.add_scalar('test_accuracy', test_accuracy, global_step)\n",
        "\n",
        "                # Just for checking progress\n",
        "                print(f'Test result of epoch {epoch}/{args.epoch} || loss : {test_loss:.3f} acc : {test_accuracy:.3f} ')\n",
        "\n",
        "                writer.flush()\n",
        "\n",
        "            # Whenever `test_accuracy` is greater than `best_accuracy`, save network weights with the filename 'best.pt' in the directory specified by `ckpt_dir`.\n",
        "            if test_accuracy > best_accuracy:\n",
        "                best_accuracy = test_accuracy\n",
        "                torch.save(net.state_dict(), f'{ckpt_dir}/{block_type}_best.pt')\n",
        "\n",
        "        scheduler.step()\n",
        "    return best_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbg5zK-d58r6"
      },
      "source": [
        "## Train Models Through the Pipeline\n",
        "\n",
        "Training a single model for 100 epochs will take around 40~50 minutes. Use this information as an indicator for your experiments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9amkLXJKvPN"
      },
      "outputs": [],
      "source": [
        "# Function for weight initialization.\n",
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.kaiming_normal_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            torch.nn.init.constant_(m.bias, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.constant_(m.weight, 1)\n",
        "        torch.nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf7OLqg7Fy1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a97d51-2124-4dc9-c945-a0f83aed8e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logs and ckpts will be saved in : /gdrive/My Drive/CS492I/assignment1/results/trial_0\n",
            "# of parameters in conv net : 510426\n",
            "Correct # of parameters in conv net : 510426\n",
            "# of parameters in resPlain net : 510426\n",
            "Correct # of parameters in resPlain net : 510426\n",
            "# of parameters in resBottleneck net : 113946\n",
            "Correct # of parameters in resBottleneck net : 113946\n",
            "# of parameters in inception net : 124026\n",
            "Correct # of parameters in inception net : 124026\n"
          ]
        }
      ],
      "source": [
        "# List of all block types we will use.\n",
        "block_types = ['conv','resPlain','resBottleneck','inception']\n",
        "\n",
        "# Create directory name.\n",
        "num_trial=0\n",
        "parent_dir = result_dir / f'trial_{num_trial}'\n",
        "while parent_dir.is_dir():\n",
        "    num_trial = int(parent_dir.name.replace('trial_',''))\n",
        "    parent_dir = result_dir / f'trial_{num_trial+1}'\n",
        "print(f'Logs and ckpts will be saved in : {parent_dir}')\n",
        "\n",
        "# Define networks\n",
        "networks = []\n",
        "for block_type in block_types:\n",
        "    if block_type == 'conv':\n",
        "        args.num_blocks = [10, 10, 10]\n",
        "    else:\n",
        "        args.num_blocks = [5, 5, 5]\n",
        "\n",
        "    if block_type == 'mlp':\n",
        "        network = MyNetworkExample(64, block_type).to(device)\n",
        "    else:\n",
        "        network = MyNetwork(args.num_filters, block_type, args.num_blocks).to(device)\n",
        "\n",
        "    network.apply(weight_init)\n",
        "    networks.append(network)\n",
        "\n",
        "# Count the number of parameters of the models.\n",
        "# You can use it as an indicator of whether you correctly implemented the model.\n",
        "\n",
        "correct_params = {'mlp' : 1649354, 'conv' : 510426, 'resPlain' : 510426, 'resBottleneck' : 113946, 'inception' : 124026}\n",
        "for block_type, net  in zip(block_types, networks):\n",
        "    # Print the number of parameters in each model.\n",
        "    num_parameters = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "    print(f'# of parameters in {block_type} net : {num_parameters}')\n",
        "    print(f'Correct # of parameters in {block_type} net : {correct_params[block_type]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKLm4c-WfwZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dfaa742-5ede-4713-8648-cb1540a10f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result of epoch 0/100 || loss : 1.868 acc : 0.307 \n",
            "Test result of epoch 1/100 || loss : 1.813 acc : 0.320 \n",
            "Test result of epoch 2/100 || loss : 1.819 acc : 0.352 \n",
            "Test result of epoch 3/100 || loss : 1.670 acc : 0.400 \n",
            "Test result of epoch 4/100 || loss : 1.499 acc : 0.447 \n",
            "Test result of epoch 5/100 || loss : 1.533 acc : 0.440 \n",
            "Test result of epoch 6/100 || loss : 1.478 acc : 0.480 \n",
            "Test result of epoch 7/100 || loss : 1.432 acc : 0.472 \n",
            "Test result of epoch 8/100 || loss : 1.232 acc : 0.556 \n",
            "Test result of epoch 9/100 || loss : 1.641 acc : 0.457 \n",
            "Test result of epoch 10/100 || loss : 1.524 acc : 0.510 \n",
            "Test result of epoch 11/100 || loss : 1.293 acc : 0.543 \n",
            "Test result of epoch 12/100 || loss : 1.442 acc : 0.502 \n",
            "Test result of epoch 13/100 || loss : 1.209 acc : 0.582 \n",
            "Test result of epoch 14/100 || loss : 1.219 acc : 0.565 \n",
            "Test result of epoch 15/100 || loss : 1.250 acc : 0.588 \n",
            "Test result of epoch 16/100 || loss : 1.057 acc : 0.630 \n",
            "Test result of epoch 17/100 || loss : 1.035 acc : 0.638 \n",
            "Test result of epoch 18/100 || loss : 1.140 acc : 0.604 \n",
            "Test result of epoch 19/100 || loss : 1.088 acc : 0.622 \n",
            "Test result of epoch 20/100 || loss : 1.084 acc : 0.630 \n",
            "Test result of epoch 21/100 || loss : 1.252 acc : 0.583 \n",
            "Test result of epoch 22/100 || loss : 0.908 acc : 0.692 \n",
            "Test result of epoch 23/100 || loss : 1.093 acc : 0.660 \n",
            "Test result of epoch 24/100 || loss : 0.969 acc : 0.662 \n",
            "Test result of epoch 25/100 || loss : 0.902 acc : 0.693 \n",
            "Test result of epoch 26/100 || loss : 1.001 acc : 0.665 \n",
            "Test result of epoch 27/100 || loss : 1.039 acc : 0.659 \n",
            "Test result of epoch 28/100 || loss : 1.011 acc : 0.662 \n",
            "Test result of epoch 29/100 || loss : 1.004 acc : 0.673 \n",
            "Test result of epoch 30/100 || loss : 0.878 acc : 0.711 \n",
            "Test result of epoch 31/100 || loss : 0.940 acc : 0.689 \n",
            "Test result of epoch 32/100 || loss : 1.143 acc : 0.640 \n",
            "Test result of epoch 33/100 || loss : 0.951 acc : 0.690 \n",
            "Test result of epoch 34/100 || loss : 0.878 acc : 0.703 \n",
            "Test result of epoch 35/100 || loss : 1.013 acc : 0.673 \n",
            "Test result of epoch 36/100 || loss : 0.801 acc : 0.731 \n",
            "Test result of epoch 37/100 || loss : 0.970 acc : 0.682 \n",
            "Test result of epoch 38/100 || loss : 0.860 acc : 0.708 \n",
            "Test result of epoch 39/100 || loss : 0.872 acc : 0.708 \n",
            "Test result of epoch 40/100 || loss : 0.829 acc : 0.724 \n",
            "Test result of epoch 41/100 || loss : 0.844 acc : 0.713 \n",
            "Test result of epoch 42/100 || loss : 0.957 acc : 0.686 \n",
            "Test result of epoch 43/100 || loss : 0.844 acc : 0.722 \n",
            "Test result of epoch 44/100 || loss : 0.809 acc : 0.728 \n",
            "Test result of epoch 45/100 || loss : 0.937 acc : 0.690 \n",
            "Test result of epoch 46/100 || loss : 1.171 acc : 0.642 \n",
            "Test result of epoch 47/100 || loss : 0.941 acc : 0.691 \n",
            "Test result of epoch 48/100 || loss : 0.916 acc : 0.700 \n",
            "Test result of epoch 49/100 || loss : 0.966 acc : 0.693 \n",
            "Test result of epoch 50/100 || loss : 0.654 acc : 0.777 \n",
            "Test result of epoch 51/100 || loss : 0.710 acc : 0.761 \n",
            "Test result of epoch 52/100 || loss : 0.681 acc : 0.775 \n",
            "Test result of epoch 53/100 || loss : 0.706 acc : 0.764 \n",
            "Test result of epoch 54/100 || loss : 0.676 acc : 0.771 \n",
            "Test result of epoch 55/100 || loss : 0.710 acc : 0.769 \n",
            "Test result of epoch 56/100 || loss : 0.691 acc : 0.775 \n",
            "Test result of epoch 57/100 || loss : 0.668 acc : 0.776 \n",
            "Test result of epoch 58/100 || loss : 0.658 acc : 0.778 \n",
            "Test result of epoch 59/100 || loss : 1.028 acc : 0.683 \n",
            "Test result of epoch 60/100 || loss : 0.671 acc : 0.776 \n",
            "Test result of epoch 61/100 || loss : 0.754 acc : 0.749 \n",
            "Test result of epoch 62/100 || loss : 0.779 acc : 0.750 \n",
            "Test result of epoch 63/100 || loss : 0.694 acc : 0.777 \n",
            "Test result of epoch 64/100 || loss : 0.659 acc : 0.775 \n",
            "Test result of epoch 65/100 || loss : 0.807 acc : 0.726 \n",
            "Test result of epoch 66/100 || loss : 0.665 acc : 0.779 \n",
            "Test result of epoch 67/100 || loss : 0.672 acc : 0.777 \n",
            "Test result of epoch 68/100 || loss : 0.647 acc : 0.785 \n",
            "Test result of epoch 69/100 || loss : 0.678 acc : 0.776 \n",
            "Test result of epoch 70/100 || loss : 0.694 acc : 0.773 \n",
            "Test result of epoch 71/100 || loss : 0.686 acc : 0.778 \n",
            "Test result of epoch 72/100 || loss : 0.683 acc : 0.775 \n",
            "Test result of epoch 73/100 || loss : 0.789 acc : 0.740 \n",
            "Test result of epoch 74/100 || loss : 0.676 acc : 0.777 \n",
            "Test result of epoch 75/100 || loss : 0.639 acc : 0.788 \n",
            "Test result of epoch 76/100 || loss : 0.735 acc : 0.759 \n",
            "Test result of epoch 77/100 || loss : 0.945 acc : 0.709 \n",
            "Test result of epoch 78/100 || loss : 0.633 acc : 0.788 \n",
            "Test result of epoch 79/100 || loss : 0.689 acc : 0.777 \n",
            "Test result of epoch 80/100 || loss : 0.577 acc : 0.807 \n",
            "Test result of epoch 81/100 || loss : 0.580 acc : 0.805 \n",
            "Test result of epoch 82/100 || loss : 0.576 acc : 0.809 \n",
            "Test result of epoch 83/100 || loss : 0.570 acc : 0.811 \n",
            "Test result of epoch 84/100 || loss : 0.556 acc : 0.814 \n",
            "Test result of epoch 85/100 || loss : 0.586 acc : 0.815 \n",
            "Test result of epoch 86/100 || loss : 0.567 acc : 0.814 \n",
            "Test result of epoch 87/100 || loss : 0.618 acc : 0.802 \n",
            "Test result of epoch 88/100 || loss : 0.575 acc : 0.812 \n",
            "Test result of epoch 89/100 || loss : 0.621 acc : 0.799 \n",
            "Test result of epoch 90/100 || loss : 0.560 acc : 0.812 \n",
            "Test result of epoch 91/100 || loss : 0.564 acc : 0.814 \n",
            "Test result of epoch 92/100 || loss : 0.572 acc : 0.810 \n",
            "Test result of epoch 93/100 || loss : 0.615 acc : 0.798 \n",
            "Test result of epoch 94/100 || loss : 0.615 acc : 0.801 \n",
            "Test result of epoch 95/100 || loss : 0.589 acc : 0.806 \n",
            "Test result of epoch 96/100 || loss : 0.585 acc : 0.807 \n",
            "Test result of epoch 97/100 || loss : 0.592 acc : 0.802 \n",
            "Test result of epoch 98/100 || loss : 0.583 acc : 0.809 \n",
            "Test result of epoch 99/100 || loss : 0.630 acc : 0.801 \n",
            "Best test accuracy of conv network : 0.815 took 2538.468 secs\n",
            "Test result of epoch 0/100 || loss : 1.670 acc : 0.390 \n",
            "Test result of epoch 1/100 || loss : 1.362 acc : 0.497 \n",
            "Test result of epoch 2/100 || loss : 1.267 acc : 0.542 \n",
            "Test result of epoch 3/100 || loss : 1.169 acc : 0.592 \n",
            "Test result of epoch 4/100 || loss : 0.968 acc : 0.653 \n",
            "Test result of epoch 5/100 || loss : 0.967 acc : 0.667 \n",
            "Test result of epoch 6/100 || loss : 0.880 acc : 0.694 \n",
            "Test result of epoch 7/100 || loss : 0.809 acc : 0.718 \n",
            "Test result of epoch 8/100 || loss : 0.750 acc : 0.737 \n",
            "Test result of epoch 9/100 || loss : 0.796 acc : 0.735 \n",
            "Test result of epoch 10/100 || loss : 0.763 acc : 0.748 \n",
            "Test result of epoch 11/100 || loss : 0.812 acc : 0.731 \n",
            "Test result of epoch 12/100 || loss : 0.619 acc : 0.780 \n",
            "Test result of epoch 13/100 || loss : 0.648 acc : 0.779 \n",
            "Test result of epoch 14/100 || loss : 0.654 acc : 0.781 \n",
            "Test result of epoch 15/100 || loss : 0.592 acc : 0.801 \n",
            "Test result of epoch 16/100 || loss : 0.563 acc : 0.807 \n",
            "Test result of epoch 17/100 || loss : 0.706 acc : 0.763 \n",
            "Test result of epoch 18/100 || loss : 0.649 acc : 0.784 \n",
            "Test result of epoch 19/100 || loss : 0.643 acc : 0.784 \n",
            "Test result of epoch 20/100 || loss : 0.562 acc : 0.810 \n",
            "Test result of epoch 21/100 || loss : 0.621 acc : 0.785 \n",
            "Test result of epoch 22/100 || loss : 0.522 acc : 0.821 \n",
            "Test result of epoch 23/100 || loss : 0.595 acc : 0.798 \n",
            "Test result of epoch 24/100 || loss : 0.563 acc : 0.807 \n",
            "Test result of epoch 25/100 || loss : 0.569 acc : 0.813 \n",
            "Test result of epoch 26/100 || loss : 0.541 acc : 0.815 \n",
            "Test result of epoch 27/100 || loss : 0.515 acc : 0.825 \n",
            "Test result of epoch 28/100 || loss : 0.568 acc : 0.811 \n",
            "Test result of epoch 29/100 || loss : 0.517 acc : 0.823 \n",
            "Test result of epoch 30/100 || loss : 0.633 acc : 0.802 \n",
            "Test result of epoch 31/100 || loss : 0.523 acc : 0.821 \n",
            "Test result of epoch 32/100 || loss : 0.494 acc : 0.833 \n",
            "Test result of epoch 33/100 || loss : 0.503 acc : 0.832 \n",
            "Test result of epoch 34/100 || loss : 0.529 acc : 0.822 \n",
            "Test result of epoch 35/100 || loss : 0.578 acc : 0.816 \n",
            "Test result of epoch 36/100 || loss : 0.525 acc : 0.829 \n",
            "Test result of epoch 37/100 || loss : 0.493 acc : 0.836 \n",
            "Test result of epoch 38/100 || loss : 0.544 acc : 0.827 \n",
            "Test result of epoch 39/100 || loss : 0.546 acc : 0.826 \n",
            "Test result of epoch 40/100 || loss : 0.524 acc : 0.825 \n",
            "Test result of epoch 41/100 || loss : 0.469 acc : 0.847 \n",
            "Test result of epoch 42/100 || loss : 0.541 acc : 0.824 \n",
            "Test result of epoch 43/100 || loss : 0.552 acc : 0.817 \n",
            "Test result of epoch 44/100 || loss : 0.505 acc : 0.832 \n",
            "Test result of epoch 45/100 || loss : 0.486 acc : 0.837 \n",
            "Test result of epoch 46/100 || loss : 0.550 acc : 0.820 \n",
            "Test result of epoch 47/100 || loss : 0.566 acc : 0.821 \n",
            "Test result of epoch 48/100 || loss : 0.486 acc : 0.841 \n",
            "Test result of epoch 49/100 || loss : 0.626 acc : 0.806 \n",
            "Test result of epoch 50/100 || loss : 0.379 acc : 0.875 \n",
            "Test result of epoch 51/100 || loss : 0.381 acc : 0.876 \n",
            "Test result of epoch 52/100 || loss : 0.414 acc : 0.869 \n",
            "Test result of epoch 53/100 || loss : 0.413 acc : 0.867 \n",
            "Test result of epoch 54/100 || loss : 0.422 acc : 0.867 \n",
            "Test result of epoch 55/100 || loss : 0.464 acc : 0.858 \n",
            "Test result of epoch 56/100 || loss : 0.394 acc : 0.876 \n",
            "Test result of epoch 57/100 || loss : 0.407 acc : 0.868 \n",
            "Test result of epoch 58/100 || loss : 0.427 acc : 0.868 \n",
            "Test result of epoch 59/100 || loss : 0.440 acc : 0.863 \n",
            "Test result of epoch 60/100 || loss : 0.454 acc : 0.860 \n",
            "Test result of epoch 61/100 || loss : 0.503 acc : 0.846 \n",
            "Test result of epoch 62/100 || loss : 0.423 acc : 0.869 \n",
            "Test result of epoch 63/100 || loss : 0.477 acc : 0.851 \n",
            "Test result of epoch 64/100 || loss : 0.428 acc : 0.865 \n",
            "Test result of epoch 65/100 || loss : 0.480 acc : 0.854 \n",
            "Test result of epoch 66/100 || loss : 0.491 acc : 0.854 \n",
            "Test result of epoch 67/100 || loss : 0.417 acc : 0.866 \n",
            "Test result of epoch 68/100 || loss : 0.433 acc : 0.859 \n",
            "Test result of epoch 69/100 || loss : 0.427 acc : 0.862 \n",
            "Test result of epoch 70/100 || loss : 0.426 acc : 0.866 \n",
            "Test result of epoch 71/100 || loss : 0.459 acc : 0.858 \n",
            "Test result of epoch 72/100 || loss : 0.427 acc : 0.866 \n",
            "Test result of epoch 73/100 || loss : 0.433 acc : 0.863 \n",
            "Test result of epoch 74/100 || loss : 0.464 acc : 0.857 \n",
            "Test result of epoch 75/100 || loss : 0.471 acc : 0.859 \n",
            "Test result of epoch 76/100 || loss : 0.430 acc : 0.867 \n",
            "Test result of epoch 77/100 || loss : 0.444 acc : 0.866 \n",
            "Test result of epoch 78/100 || loss : 0.453 acc : 0.859 \n",
            "Test result of epoch 79/100 || loss : 0.442 acc : 0.863 \n",
            "Test result of epoch 80/100 || loss : 0.400 acc : 0.881 \n",
            "Test result of epoch 81/100 || loss : 0.410 acc : 0.881 \n",
            "Test result of epoch 82/100 || loss : 0.403 acc : 0.884 \n",
            "Test result of epoch 83/100 || loss : 0.416 acc : 0.880 \n",
            "Test result of epoch 84/100 || loss : 0.397 acc : 0.885 \n",
            "Test result of epoch 85/100 || loss : 0.412 acc : 0.882 \n",
            "Test result of epoch 86/100 || loss : 0.411 acc : 0.882 \n",
            "Test result of epoch 87/100 || loss : 0.427 acc : 0.877 \n",
            "Test result of epoch 88/100 || loss : 0.469 acc : 0.870 \n",
            "Test result of epoch 89/100 || loss : 0.431 acc : 0.879 \n",
            "Test result of epoch 90/100 || loss : 0.454 acc : 0.876 \n",
            "Test result of epoch 91/100 || loss : 0.454 acc : 0.873 \n",
            "Test result of epoch 92/100 || loss : 0.433 acc : 0.878 \n",
            "Test result of epoch 93/100 || loss : 0.450 acc : 0.875 \n",
            "Test result of epoch 94/100 || loss : 0.438 acc : 0.880 \n",
            "Test result of epoch 95/100 || loss : 0.443 acc : 0.879 \n",
            "Test result of epoch 96/100 || loss : 0.445 acc : 0.878 \n",
            "Test result of epoch 97/100 || loss : 0.424 acc : 0.883 \n",
            "Test result of epoch 98/100 || loss : 0.438 acc : 0.881 \n",
            "Test result of epoch 99/100 || loss : 0.449 acc : 0.877 \n",
            "Best test accuracy of resPlain network : 0.885 took 2504.809 secs\n",
            "Test result of epoch 0/100 || loss : 1.641 acc : 0.379 \n",
            "Test result of epoch 1/100 || loss : 1.370 acc : 0.501 \n",
            "Test result of epoch 2/100 || loss : 1.292 acc : 0.537 \n",
            "Test result of epoch 3/100 || loss : 1.189 acc : 0.581 \n",
            "Test result of epoch 4/100 || loss : 1.306 acc : 0.565 \n",
            "Test result of epoch 5/100 || loss : 1.020 acc : 0.643 \n",
            "Test result of epoch 6/100 || loss : 0.996 acc : 0.652 \n",
            "Test result of epoch 7/100 || loss : 1.024 acc : 0.662 \n",
            "Test result of epoch 8/100 || loss : 0.935 acc : 0.677 \n",
            "Test result of epoch 9/100 || loss : 0.918 acc : 0.699 \n",
            "Test result of epoch 10/100 || loss : 0.926 acc : 0.691 \n",
            "Test result of epoch 11/100 || loss : 0.950 acc : 0.690 \n",
            "Test result of epoch 12/100 || loss : 0.844 acc : 0.718 \n",
            "Test result of epoch 13/100 || loss : 0.770 acc : 0.732 \n",
            "Test result of epoch 14/100 || loss : 0.787 acc : 0.733 \n",
            "Test result of epoch 15/100 || loss : 0.685 acc : 0.762 \n",
            "Test result of epoch 16/100 || loss : 0.746 acc : 0.750 \n",
            "Test result of epoch 17/100 || loss : 0.796 acc : 0.734 \n",
            "Test result of epoch 18/100 || loss : 0.757 acc : 0.743 \n",
            "Test result of epoch 19/100 || loss : 0.757 acc : 0.746 \n",
            "Test result of epoch 20/100 || loss : 0.685 acc : 0.775 \n",
            "Test result of epoch 21/100 || loss : 0.655 acc : 0.777 \n",
            "Test result of epoch 22/100 || loss : 0.695 acc : 0.765 \n",
            "Test result of epoch 23/100 || loss : 0.718 acc : 0.762 \n",
            "Test result of epoch 24/100 || loss : 0.831 acc : 0.716 \n",
            "Test result of epoch 25/100 || loss : 0.827 acc : 0.737 \n",
            "Test result of epoch 26/100 || loss : 0.644 acc : 0.785 \n",
            "Test result of epoch 27/100 || loss : 0.655 acc : 0.775 \n",
            "Test result of epoch 28/100 || loss : 0.640 acc : 0.784 \n",
            "Test result of epoch 29/100 || loss : 0.626 acc : 0.789 \n",
            "Test result of epoch 30/100 || loss : 0.675 acc : 0.782 \n",
            "Test result of epoch 31/100 || loss : 0.639 acc : 0.789 \n",
            "Test result of epoch 32/100 || loss : 0.639 acc : 0.784 \n",
            "Test result of epoch 33/100 || loss : 0.604 acc : 0.799 \n",
            "Test result of epoch 34/100 || loss : 0.708 acc : 0.776 \n",
            "Test result of epoch 35/100 || loss : 0.790 acc : 0.747 \n",
            "Test result of epoch 36/100 || loss : 0.595 acc : 0.800 \n",
            "Test result of epoch 37/100 || loss : 0.639 acc : 0.786 \n",
            "Test result of epoch 38/100 || loss : 0.585 acc : 0.798 \n",
            "Test result of epoch 39/100 || loss : 0.766 acc : 0.767 \n",
            "Test result of epoch 40/100 || loss : 0.647 acc : 0.782 \n",
            "Test result of epoch 41/100 || loss : 0.620 acc : 0.788 \n",
            "Test result of epoch 42/100 || loss : 0.587 acc : 0.806 \n",
            "Test result of epoch 43/100 || loss : 0.679 acc : 0.774 \n",
            "Test result of epoch 44/100 || loss : 0.611 acc : 0.794 \n",
            "Test result of epoch 45/100 || loss : 0.625 acc : 0.798 \n",
            "Test result of epoch 46/100 || loss : 0.600 acc : 0.797 \n",
            "Test result of epoch 47/100 || loss : 0.636 acc : 0.789 \n",
            "Test result of epoch 48/100 || loss : 0.704 acc : 0.772 \n",
            "Test result of epoch 49/100 || loss : 0.610 acc : 0.799 \n",
            "Test result of epoch 50/100 || loss : 0.477 acc : 0.836 \n",
            "Test result of epoch 51/100 || loss : 0.482 acc : 0.837 \n",
            "Test result of epoch 52/100 || loss : 0.462 acc : 0.846 \n",
            "Test result of epoch 53/100 || loss : 0.489 acc : 0.835 \n",
            "Test result of epoch 54/100 || loss : 0.471 acc : 0.843 \n",
            "Test result of epoch 55/100 || loss : 0.487 acc : 0.838 \n",
            "Test result of epoch 56/100 || loss : 0.510 acc : 0.829 \n",
            "Test result of epoch 57/100 || loss : 0.471 acc : 0.839 \n",
            "Test result of epoch 58/100 || loss : 0.468 acc : 0.844 \n",
            "Test result of epoch 59/100 || loss : 0.472 acc : 0.840 \n",
            "Test result of epoch 60/100 || loss : 0.492 acc : 0.839 \n",
            "Test result of epoch 61/100 || loss : 0.479 acc : 0.843 \n",
            "Test result of epoch 62/100 || loss : 0.526 acc : 0.824 \n",
            "Test result of epoch 63/100 || loss : 0.607 acc : 0.809 \n",
            "Test result of epoch 64/100 || loss : 0.487 acc : 0.833 \n",
            "Test result of epoch 65/100 || loss : 0.448 acc : 0.850 \n",
            "Test result of epoch 66/100 || loss : 0.481 acc : 0.838 \n",
            "Test result of epoch 67/100 || loss : 0.528 acc : 0.830 \n",
            "Test result of epoch 68/100 || loss : 0.531 acc : 0.823 \n",
            "Test result of epoch 69/100 || loss : 0.550 acc : 0.821 \n",
            "Test result of epoch 70/100 || loss : 0.495 acc : 0.835 \n",
            "Test result of epoch 71/100 || loss : 0.510 acc : 0.831 \n",
            "Test result of epoch 72/100 || loss : 0.515 acc : 0.832 \n",
            "Test result of epoch 73/100 || loss : 0.473 acc : 0.842 \n",
            "Test result of epoch 74/100 || loss : 0.519 acc : 0.827 \n",
            "Test result of epoch 75/100 || loss : 0.513 acc : 0.832 \n",
            "Test result of epoch 76/100 || loss : 0.493 acc : 0.839 \n",
            "Test result of epoch 77/100 || loss : 0.490 acc : 0.839 \n",
            "Test result of epoch 78/100 || loss : 0.489 acc : 0.839 \n",
            "Test result of epoch 79/100 || loss : 0.502 acc : 0.834 \n",
            "Test result of epoch 80/100 || loss : 0.471 acc : 0.848 \n",
            "Test result of epoch 81/100 || loss : 0.424 acc : 0.859 \n",
            "Test result of epoch 82/100 || loss : 0.431 acc : 0.855 \n",
            "Test result of epoch 83/100 || loss : 0.439 acc : 0.854 \n",
            "Test result of epoch 84/100 || loss : 0.434 acc : 0.859 \n",
            "Test result of epoch 85/100 || loss : 0.441 acc : 0.858 \n",
            "Test result of epoch 86/100 || loss : 0.434 acc : 0.858 \n",
            "Test result of epoch 87/100 || loss : 0.425 acc : 0.861 \n",
            "Test result of epoch 88/100 || loss : 0.433 acc : 0.860 \n",
            "Test result of epoch 89/100 || loss : 0.443 acc : 0.862 \n",
            "Test result of epoch 90/100 || loss : 0.434 acc : 0.857 \n",
            "Test result of epoch 91/100 || loss : 0.466 acc : 0.851 \n",
            "Test result of epoch 92/100 || loss : 0.452 acc : 0.859 \n",
            "Test result of epoch 93/100 || loss : 0.480 acc : 0.846 \n",
            "Test result of epoch 94/100 || loss : 0.427 acc : 0.863 \n",
            "Test result of epoch 95/100 || loss : 0.468 acc : 0.853 \n",
            "Test result of epoch 96/100 || loss : 0.447 acc : 0.858 \n",
            "Test result of epoch 97/100 || loss : 0.439 acc : 0.861 \n",
            "Test result of epoch 98/100 || loss : 0.436 acc : 0.859 \n",
            "Test result of epoch 99/100 || loss : 0.450 acc : 0.856 \n",
            "Best test accuracy of resBottleneck network : 0.863 took 2719.105 secs\n",
            "Test result of epoch 0/100 || loss : 1.767 acc : 0.343 \n",
            "Test result of epoch 1/100 || loss : 1.573 acc : 0.418 \n",
            "Test result of epoch 2/100 || loss : 1.464 acc : 0.463 \n",
            "Test result of epoch 3/100 || loss : 1.443 acc : 0.471 \n",
            "Test result of epoch 4/100 || loss : 1.340 acc : 0.517 \n",
            "Test result of epoch 5/100 || loss : 1.449 acc : 0.487 \n",
            "Test result of epoch 6/100 || loss : 1.335 acc : 0.538 \n",
            "Test result of epoch 7/100 || loss : 1.239 acc : 0.559 \n",
            "Test result of epoch 8/100 || loss : 1.167 acc : 0.584 \n",
            "Test result of epoch 9/100 || loss : 1.157 acc : 0.592 \n",
            "Test result of epoch 10/100 || loss : 1.122 acc : 0.612 \n",
            "Test result of epoch 11/100 || loss : 1.061 acc : 0.622 \n",
            "Test result of epoch 12/100 || loss : 1.037 acc : 0.632 \n",
            "Test result of epoch 13/100 || loss : 1.160 acc : 0.601 \n",
            "Test result of epoch 14/100 || loss : 1.122 acc : 0.609 \n",
            "Test result of epoch 15/100 || loss : 1.045 acc : 0.641 \n",
            "Test result of epoch 16/100 || loss : 0.909 acc : 0.686 \n",
            "Test result of epoch 17/100 || loss : 1.055 acc : 0.646 \n",
            "Test result of epoch 18/100 || loss : 0.931 acc : 0.677 \n",
            "Test result of epoch 19/100 || loss : 1.078 acc : 0.637 \n",
            "Test result of epoch 20/100 || loss : 0.872 acc : 0.705 \n",
            "Test result of epoch 21/100 || loss : 0.920 acc : 0.680 \n",
            "Test result of epoch 22/100 || loss : 0.851 acc : 0.702 \n",
            "Test result of epoch 23/100 || loss : 0.876 acc : 0.704 \n",
            "Test result of epoch 24/100 || loss : 0.805 acc : 0.718 \n",
            "Test result of epoch 25/100 || loss : 0.839 acc : 0.714 \n",
            "Test result of epoch 26/100 || loss : 0.783 acc : 0.734 \n",
            "Test result of epoch 27/100 || loss : 0.784 acc : 0.730 \n",
            "Test result of epoch 28/100 || loss : 0.765 acc : 0.735 \n",
            "Test result of epoch 29/100 || loss : 0.953 acc : 0.685 \n",
            "Test result of epoch 30/100 || loss : 0.869 acc : 0.703 \n",
            "Test result of epoch 31/100 || loss : 0.807 acc : 0.730 \n",
            "Test result of epoch 32/100 || loss : 0.798 acc : 0.728 \n",
            "Test result of epoch 33/100 || loss : 0.980 acc : 0.682 \n",
            "Test result of epoch 34/100 || loss : 0.897 acc : 0.704 \n",
            "Test result of epoch 35/100 || loss : 0.723 acc : 0.748 \n",
            "Test result of epoch 36/100 || loss : 0.841 acc : 0.722 \n",
            "Test result of epoch 37/100 || loss : 0.832 acc : 0.723 \n",
            "Test result of epoch 38/100 || loss : 0.777 acc : 0.747 \n",
            "Test result of epoch 39/100 || loss : 0.850 acc : 0.719 \n",
            "Test result of epoch 40/100 || loss : 0.849 acc : 0.714 \n",
            "Test result of epoch 41/100 || loss : 0.818 acc : 0.719 \n",
            "Test result of epoch 42/100 || loss : 0.745 acc : 0.746 \n",
            "Test result of epoch 43/100 || loss : 0.963 acc : 0.681 \n",
            "Test result of epoch 44/100 || loss : 0.969 acc : 0.691 \n",
            "Test result of epoch 45/100 || loss : 0.954 acc : 0.699 \n",
            "Test result of epoch 46/100 || loss : 0.747 acc : 0.745 \n",
            "Test result of epoch 47/100 || loss : 0.919 acc : 0.690 \n",
            "Test result of epoch 48/100 || loss : 0.815 acc : 0.737 \n",
            "Test result of epoch 49/100 || loss : 0.766 acc : 0.742 \n",
            "Test result of epoch 50/100 || loss : 0.557 acc : 0.807 \n",
            "Test result of epoch 51/100 || loss : 0.568 acc : 0.806 \n",
            "Test result of epoch 52/100 || loss : 0.579 acc : 0.803 \n",
            "Test result of epoch 53/100 || loss : 0.575 acc : 0.808 \n",
            "Test result of epoch 54/100 || loss : 0.612 acc : 0.789 \n",
            "Test result of epoch 55/100 || loss : 0.581 acc : 0.805 \n",
            "Test result of epoch 56/100 || loss : 0.575 acc : 0.806 \n",
            "Test result of epoch 57/100 || loss : 0.629 acc : 0.786 \n",
            "Test result of epoch 58/100 || loss : 0.617 acc : 0.794 \n",
            "Test result of epoch 59/100 || loss : 0.597 acc : 0.797 \n",
            "Test result of epoch 60/100 || loss : 0.613 acc : 0.793 \n",
            "Test result of epoch 61/100 || loss : 0.648 acc : 0.780 \n",
            "Test result of epoch 62/100 || loss : 0.618 acc : 0.794 \n",
            "Test result of epoch 63/100 || loss : 0.614 acc : 0.788 \n",
            "Test result of epoch 64/100 || loss : 0.599 acc : 0.801 \n",
            "Test result of epoch 65/100 || loss : 0.577 acc : 0.806 \n",
            "Test result of epoch 66/100 || loss : 0.725 acc : 0.765 \n",
            "Test result of epoch 67/100 || loss : 0.660 acc : 0.785 \n",
            "Test result of epoch 68/100 || loss : 0.605 acc : 0.798 \n",
            "Test result of epoch 69/100 || loss : 0.573 acc : 0.806 \n",
            "Test result of epoch 70/100 || loss : 0.691 acc : 0.779 \n",
            "Test result of epoch 71/100 || loss : 0.631 acc : 0.790 \n",
            "Test result of epoch 72/100 || loss : 0.577 acc : 0.800 \n",
            "Test result of epoch 73/100 || loss : 0.591 acc : 0.802 \n",
            "Test result of epoch 74/100 || loss : 0.687 acc : 0.775 \n",
            "Test result of epoch 75/100 || loss : 0.582 acc : 0.804 \n",
            "Test result of epoch 76/100 || loss : 0.623 acc : 0.793 \n",
            "Test result of epoch 77/100 || loss : 0.640 acc : 0.783 \n",
            "Test result of epoch 78/100 || loss : 0.658 acc : 0.782 \n",
            "Test result of epoch 79/100 || loss : 0.545 acc : 0.811 \n",
            "Test result of epoch 80/100 || loss : 0.499 acc : 0.834 \n",
            "Test result of epoch 81/100 || loss : 0.513 acc : 0.830 \n",
            "Test result of epoch 82/100 || loss : 0.489 acc : 0.836 \n",
            "Test result of epoch 83/100 || loss : 0.483 acc : 0.836 \n",
            "Test result of epoch 84/100 || loss : 0.498 acc : 0.832 \n",
            "Test result of epoch 85/100 || loss : 0.509 acc : 0.828 \n",
            "Test result of epoch 86/100 || loss : 0.490 acc : 0.837 \n",
            "Test result of epoch 87/100 || loss : 0.509 acc : 0.826 \n",
            "Test result of epoch 88/100 || loss : 0.489 acc : 0.835 \n",
            "Test result of epoch 89/100 || loss : 0.537 acc : 0.821 \n",
            "Test result of epoch 90/100 || loss : 0.501 acc : 0.833 \n",
            "Test result of epoch 91/100 || loss : 0.523 acc : 0.823 \n",
            "Test result of epoch 92/100 || loss : 0.470 acc : 0.845 \n",
            "Test result of epoch 93/100 || loss : 0.520 acc : 0.823 \n",
            "Test result of epoch 94/100 || loss : 0.514 acc : 0.832 \n",
            "Test result of epoch 95/100 || loss : 0.499 acc : 0.832 \n",
            "Test result of epoch 96/100 || loss : 0.531 acc : 0.824 \n",
            "Test result of epoch 97/100 || loss : 0.525 acc : 0.826 \n",
            "Test result of epoch 98/100 || loss : 0.486 acc : 0.835 \n",
            "Test result of epoch 99/100 || loss : 0.549 acc : 0.821 \n",
            "Best test accuracy of inception network : 0.845 took 3644.190 secs\n",
            "Best accuracy of conv = 81.48%\n",
            "Best accuracy of resPlain = 88.48%\n",
            "Best accuracy of resBottleneck = 86.34%\n",
            "Best accuracy of inception = 84.51%\n"
          ]
        }
      ],
      "source": [
        "final_accs = {}\n",
        "\n",
        "# Start training\n",
        "for block_type, net in zip(block_types, networks):\n",
        "    try:\n",
        "        args.name = block_type\n",
        "\n",
        "        # Define optimizer\n",
        "        optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=0.9, weight_decay=0.0001)\n",
        "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50,80], gamma=0.5)\n",
        "\n",
        "        # Create directories for logs and ckechpoints.\n",
        "        ckpt_dir = parent_dir / args.name / args.ckpt_dir\n",
        "        ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "        log_dir = parent_dir / args.name / args.log_dir\n",
        "        log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Create tensorboard writer,\n",
        "        if args.tensorboard:\n",
        "            writer = SummaryWriter(log_dir)\n",
        "\n",
        "        # Call the train & test function.\n",
        "        t1 = time.time()\n",
        "        accuracy = train_net(net, optimizer, scheduler, block_type, writer)\n",
        "        t = time.time()-t1\n",
        "        print(f'Best test accuracy of {block_type} network : {accuracy:.3f} took {t:.3f} secs')\n",
        "        final_accs[f'{block_type}'] = accuracy*100\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "# Print final best accuracies of the models.\n",
        "for key in final_accs.keys():\n",
        "    print(f'Best accuracy of {key} = {final_accs[key]:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z1APMygJ8Um"
      },
      "source": [
        "---\n",
        "# 3.Aggregating experimental results and number of model parameters. (10pt)\n",
        "\n",
        "In this section, we automatically collect the classification performance of trained model. Also, we will count the number of parameters in the models.\n",
        "You should match your own results with the values we provided. While the number of the parameters should be exactly same, classification accuarcy should be in the range of $\\pm$1.5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MUJpr2SHYg_"
      },
      "outputs": [],
      "source": [
        "block_types = ['conv','resPlain','resBottleneck','inception']\n",
        "test_accs = {}\n",
        "test_params= {}\n",
        "\n",
        "for block_type, net in zip(block_types, networks):\n",
        "        ckpt_dir = parent_dir / block_type / args.ckpt_dir\n",
        "\n",
        "        # load weights from best checkpoints.\n",
        "        ckpt_path = f'{ckpt_dir}/{block_type}_best.pt'\n",
        "        try:\n",
        "            net.load_state_dict(torch.load(ckpt_path))\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "\n",
        "        # Measure test performance.\n",
        "        net.eval()\n",
        "        with torch.no_grad():\n",
        "            test_accuracy = 0.\n",
        "            test_num_data = 0.\n",
        "            for batch_idx, (x, y) in enumerate(test_dataloader):\n",
        "                # Send `x` and `y` to either cpu or gpu using `device` variable..\n",
        "                x = x.to(device=device)\n",
        "                y = y.to(device=device)\n",
        "\n",
        "                # Feed `x` into the network, get an output, and keep it in a variable called `logit`.\n",
        "                logit = net(x)\n",
        "\n",
        "                # Compute loss using `logit` and `y`, and keep it in a variable called `loss`.\n",
        "                loss = nn.CrossEntropyLoss()(logit, y)\n",
        "\n",
        "                # Compute accuracy of this batch using `logit`, and keep it in a variable called 'accuracy'.\n",
        "                accuracy = (logit.argmax(dim=1) == y).float().mean()\n",
        "\n",
        "                test_accuracy += accuracy.item()*x.shape[0]\n",
        "                test_num_data += x.shape[0]\n",
        "\n",
        "            # Average classification accuracy.\n",
        "            test_accuracy /= test_num_data\n",
        "\n",
        "            # Count the number of implemented models.\n",
        "            num_parameters = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "\n",
        "            test_accs[f'{block_type}'] = test_accuracy*100\n",
        "            test_params[f'{block_type}'] = num_parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuQ_VHdpXbXz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d771ac-07e7-4391-980b-5e8ab9e00e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Method        | Accuracy   | # Params    | Expected Acc | Expected # Params  \n",
            "------------------------------------------------------------------------------\n",
            " conv          | 81.47      | 510426      | 81.9         | 510426      \n",
            " resPlain      | 88.48      | 510426      | 88.6         | 510426      \n",
            " resBottleneck | 86.33      | 113946      | 86.5         | 113946      \n",
            " inception     | 84.50      | 124026      | 83.7         | 124026      \n"
          ]
        }
      ],
      "source": [
        "# Printing final results.\n",
        "correct_accs = {'mlp' : 62.6,'conv' : 81.9,'resPlain' : 88.6, 'resBottleneck' : 86.5, 'inception' : 83.7}\n",
        "correct_params = {'mlp' : 1649354, 'conv' : 510426, 'resPlain' : 510426, 'resBottleneck' : 113946, 'inception' : 124026}\n",
        "\n",
        "print(' Method        | Accuracy   | # Params    | Expected Acc | Expected # Params  ')\n",
        "print('------------------------------------------------------------------------------')\n",
        "for block in block_types:\n",
        "        print(f' {block:14}| {str(test_accs[block])[:5]:11}| {str(test_params[block]):11} | {str(correct_accs[block])[:5]:13}| {str(correct_params[block]):12}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "I3NY7sfLled4",
        "PILjK1Nmx2M6",
        "1eLCjNVBx2sd",
        "fjz2alvvyr6T",
        "f0yAzCxaysW0",
        "TkXfj1KsytsU",
        "yXSb4yHIYURW",
        "fbSoxtKYU_gG",
        "ZcFgC8fd4gsr",
        "KqZmn8qQdBji"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f62ee4785cbf45b091fd60eeb9bbabc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd2fa7ae77f0401c95f91f341e9b79de",
              "IPY_MODEL_bb67ef30359040d786182eb6bb66e8fc",
              "IPY_MODEL_84aa8f6385694afb9ca4344f396f2421"
            ],
            "layout": "IPY_MODEL_ea21326b532c4b10999496a8f8a2b0ef"
          }
        },
        "fd2fa7ae77f0401c95f91f341e9b79de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b57a13481e5442fb98e0a9d47572090",
            "placeholder": "​",
            "style": "IPY_MODEL_83357e5c6c8c4ed1a71f2d3a98727511",
            "value": "100%"
          }
        },
        "bb67ef30359040d786182eb6bb66e8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95dcaf479aa646da92b3c1b6fb4ec87c",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdcb5a5b8d3546389c919f476e954b26",
            "value": 170498071
          }
        },
        "84aa8f6385694afb9ca4344f396f2421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26489d53690e4e0b881c394fcef52d75",
            "placeholder": "​",
            "style": "IPY_MODEL_f4f6f75e5881442f903e3b5176b03083",
            "value": " 170498071/170498071 [00:03&lt;00:00, 55178376.17it/s]"
          }
        },
        "ea21326b532c4b10999496a8f8a2b0ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b57a13481e5442fb98e0a9d47572090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83357e5c6c8c4ed1a71f2d3a98727511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95dcaf479aa646da92b3c1b6fb4ec87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdcb5a5b8d3546389c919f476e954b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26489d53690e4e0b881c394fcef52d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4f6f75e5881442f903e3b5176b03083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}